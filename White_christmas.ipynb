{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prerequisties\n",
        "- We will be running Mask R-CNN on Detectron2, and load the pre-trained Mask R-CNN model\n",
        "- The model predicts bounding boxes and many classes, we will filter class \"person\" only with index \"0\"\n",
        "- We will then mask the pred_segments with random gray noises"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqt953zPhy3Y",
        "outputId": "a6253a82-bf0a-4d8b-99cd-e335dc5b2e85"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone https://github.com/facebookresearch/detectron2\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bn2m4Uah3QF",
        "outputId": "22ab083b-08d0-481c-d06f-3642718544dd"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "!wget https://i.ibb.co/d6msyFW/input.jpg -q -O input.jpg\n",
        "im = cv2.imread(\"./input.jpg\")\n",
        "cv2_imshow(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3B8lvTimyd47"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "import cv2\n",
        "import time"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PiqTfd3zh7S-"
      },
      "source": [
        "# Gray out persons for images\n",
        "- Configure and load the detectron2 Mask R-CNN model\n",
        "- Masks the segmented predictoins with gray noise\n",
        "- Save the resulting masked image as masked_image.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up detector2 model and configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold for the object detection\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "def get_frame_prediction(image):\n",
        "    # Predict the objects in the image with detectron2\n",
        "    outputs = predictor(image)\n",
        "\n",
        "    # Filter the object detections to find people\n",
        "    person_indices = np.where(outputs[\"instances\"].pred_classes.cpu() == 0)[0]\n",
        "\n",
        "    # Create a white noise image the same size as the original\n",
        "    noise = np.random.randint(0, 256, (image.shape[0], image.shape[1], 1)).astype(np.uint8)\n",
        "    noise = np.repeat(noise, 3, axis=2)\n",
        "\n",
        "    # Apply a segmented white noise mask to the image for each person detected\n",
        "    for i in person_indices:\n",
        "        noise = np.random.randint(0, 256, (image.shape[0], image.shape[1], 1)).astype(np.uint8)\n",
        "        noise = np.repeat(noise, 3, axis=2)\n",
        "        mask_np = outputs[\"instances\"].pred_masks.cpu().numpy()[i]\n",
        "        mask_np = np.expand_dims(mask_np, axis=-1)\n",
        "        mask_np = np.repeat(mask_np, 3, axis=2)\n",
        "        masked_noise = np.multiply(noise, mask_np)\n",
        "        image = np.where(mask_np == 1, masked_noise.astype(np.uint8), image)\n",
        "        \n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A7Y8Qatvh5YG",
        "outputId": "6874c40a-9bb1-47dc-cdcf-011c3bdf2194"
      },
      "outputs": [],
      "source": [
        "# Load the image\n",
        "image = np.array(Image.open(\"./input.jpg\"))\n",
        "\n",
        "# Run detectron2 on the image\n",
        "masked_image = get_frame_prediction(image)\n",
        "\n",
        "# Show the resulting image\n",
        "cv2_imshow(get_frame_prediction(image))\n",
        "\n",
        "# Save the resulting masked image\n",
        "masked_image = Image.fromarray(masked_image.astype(np.uint8))\n",
        "masked_image.save('masked_image.jpg')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I2GvbvN5iL3Q"
      },
      "source": [
        "# Video input for the model\n",
        "- Downloads ForBiggerEscapes.mp4 from github\n",
        "- Applies our algorithm and saves the results as masked_video.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4x19QAaiRAx",
        "outputId": "28749a86-10ba-4c0a-eeef-84d3f1c99324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-06 11:18:05--  http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerEscapes.mp4\n",
            "Resolving commondatastorage.googleapis.com (commondatastorage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to commondatastorage.googleapis.com (commondatastorage.googleapis.com)|74.125.142.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2299653 (2.2M) [video/mp4]\n",
            "Saving to: ‘ForBiggerEscapes.mp4.1’\n",
            "\n",
            "\rForBiggerEscapes.mp   0%[                    ]       0  --.-KB/s               \rForBiggerEscapes.mp 100%[===================>]   2.19M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-05-06 11:18:05 (121 MB/s) - ‘ForBiggerEscapes.mp4.1’ saved [2299653/2299653]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Thanks to sample free video urls on github https://gist.github.com/deepakpk009/99fd994da714996b296f11c3c371d5ee\n",
        "!wget http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ForBiggerEscapes.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m35Y9tRiOlS",
        "outputId": "14e66f39-2704-4b02-a48d-68b55a4dbad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 360/360\n",
            "The code took 62.507 seconds to run.\n"
          ]
        }
      ],
      "source": [
        "##### You can skip the model loading if you've already ran the images section #####\n",
        "# Set up detector2 model and configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold for the object detection\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "###################################################################################\n",
        "\n",
        "# Load the video\n",
        "video = cv2.VideoCapture(\"ForBiggerBlazes.mp4\")\n",
        "\n",
        "# Get the codec and frame size of the video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "frame_size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "# Create a writer object to save the masked video\n",
        "out = cv2.VideoWriter(\"masked_video.mp4\", fourcc, fps, frame_size)\n",
        "\n",
        "# Define number of frames for progress estimation\n",
        "max_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "length = 0\n",
        "\n",
        "# Define the time when the code started running\n",
        "start_time = time.time()\n",
        "\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = video.read()\n",
        "    \n",
        "    if not ret:\n",
        "        # Break out of the loop if no more frames left\n",
        "        break\n",
        "    \n",
        "    # Predict the objects in the image with detectron2\n",
        "    outputs = predictor(frame)\n",
        "    \n",
        "    # Filter the object detections to find people\n",
        "    person_indices = np.where(outputs[\"instances\"].pred_classes.cpu() == 0)[0]\n",
        "    \n",
        "    # Create a grayscale noise image the same size as the current frame\n",
        "    noise = np.random.randint(0, 256, (frame.shape[0], frame.shape[1], 1)).astype(np.uint8)\n",
        "    \n",
        "    # Repeat noise across all three channels\n",
        "    noise = np.repeat(noise, 3, axis=2)\n",
        "    \n",
        "    # Apply a segmented grayscale noise mask to the image for each person detected\n",
        "    for i in person_indices:\n",
        "        mask_np = outputs[\"instances\"].pred_masks.cpu().numpy()[i]\n",
        "        mask_np = np.expand_dims(mask_np, axis=-1)\n",
        "        mask_np = np.repeat(mask_np, 3, axis=2)\n",
        "        masked_noise = np.multiply(noise, mask_np)\n",
        "        frame = np.where(mask_np == 1, masked_noise.astype(np.uint8), frame)\n",
        "    \n",
        "    # Write the resulting frame to the output video file\n",
        "    out.write(frame)\n",
        "    length = length + 1\n",
        "\n",
        "    print(f\"\\rProgress: {length}/\" + str(max_frames), end=\"\", flush=True)\n",
        "\n",
        "# end the timer\n",
        "end_time = time.time()\n",
        "\n",
        "# calculate the time taken\n",
        "elapsed_time = end_time - start_time\n",
        "print()\n",
        "print(f\"The code took {elapsed_time:.3f} seconds to run.\")\n",
        "\n",
        "# Release the video capture and writer objects\n",
        "video.release()\n",
        "out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
